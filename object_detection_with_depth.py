# realtime_yolo_trt_save.py
from ultralytics import YOLO
import cv2, time, datetime, os
from pathlib import Path
from Depth_Anything_for_Jetson_Orin.depth_with_yolo import DepthEngine

import zmq
import json


# ========= ì‚¬ìš©ì ì„¤ì • =========
ENGINE_PATH     = "/home/ircv7/Embedded/Project_1/tensorrt_engine/250521_n_detection.engine"
SAVE_DIR        = Path("runs")               # ì´ë¯¸ì§€Â·ë™ì˜ìƒ ì €ì¥ í´ë”
SAVE_VIDEO      = False                       # ì˜ìƒ ì €ì¥ í™œì„±í™”
VIDEO_NAME      = "yolo_depth_output.mp4"    # ì €ì¥ë  ë¹„ë””ì˜¤ íŒŒì¼ëª…
VIDEO_FPS       = 5                          # ë¹„ë””ì˜¤ ì €ì¥ FPS
# =================================


def gstreamer_pipeline(sensor_id=1, width=960, height=540,
                       display_width=960, display_height=540,
                       framerate=30, flip_method=0):
    return (
        "nvarguscamerasrc sensor-id=%d ! "
        "video/x-raw(memory:NVMM), width=(int)%d, height=(int)%d, format=(string)NV12, framerate=(fraction)%d/1 ! "
        "nvvidconv ! "
        "video/x-raw, format=(string)BGRx ! "
        "videoconvert ! "
        "video/x-raw, format=(string)BGR ! "
        "appsink max-buffers=1 drop=True"
        % (
            sensor_id,
            width,
            height,
            framerate,
        )
    )


def main():
    # --- ZMQ PUB ì´ˆê¸°í™” === ADDED ===
    ctx   = zmq.Context()
    pub   = ctx.socket(zmq.PUB)
    pub.bind("tcp://*:5555")  # ì›í•˜ëŠ” í¬íŠ¸ë¡œ ë³€ê²½ ê°€ëŠ¥
    # ========================

    # --- ì €ì¥ì„ ìœ„í•œ VideoWriter ì´ˆê¸°í™” ---
    video_writer = None
    if SAVE_VIDEO:
        SAVE_DIR.mkdir(parents=True, exist_ok=True)
    
    # --- ì´ˆê¸°í™” ---
    cap = cv2.VideoCapture(gstreamer_pipeline(), cv2.CAP_GSTREAMER)
    if not cap.isOpened():
        raise RuntimeError("âŒ ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨")

    ok, frame = cap.read()
    if not ok:
        raise RuntimeError("ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # VideoWriter íŒŒë¼ë¯¸í„° ì„¤ì •
    if SAVE_VIDEO:
        height, width = frame.shape[:2]
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out_path = SAVE_DIR / VIDEO_NAME
        video_writer = cv2.VideoWriter(str(out_path), fourcc, VIDEO_FPS, (width, height))
        print(f"ğŸ¥ Saving video to {out_path}")

    print("============INFERENCE START==================")
    depth = DepthEngine(
        frame_rate=10,
        raw=True,
        stream=False, 
        record=False,
        save=False, 
        grayscale=False
    )
    # depth._width, depth._height = 1280, 720
    
    yolo_model = YOLO(ENGINE_PATH)
    frame_idx = 0

    try:
        while True:
            ok, frame = cap.read()
            if not ok:
                print("âš ï¸  í”„ë ˆì„ ìˆ˜ì‹  ì‹¤íŒ¨ â€“ ì¢…ë£Œ")
                break

            if frame_idx % 5 == 0:                    # N frame inference
                # --- YOLO ì¶”ë¡  ---
                bbox_result = yolo_model(frame, imgsz=640, conf=0.45)[0]
                boxes = bbox_result.boxes.xyxy.cpu().numpy()
                classes = bbox_result.boxes.cls.cpu().numpy()
                depth_map = depth.infer(frame)

                msgs = []
                for i, (x1, y1, x2, y2) in enumerate(boxes):
                    cx = int((x1 + x2) / 2)
                    cy = int((y1 + y2) / 2)
                    depth_val = float(depth_map[cy, cx].item())
                    print(f"[Object {i}] center=({cx},{cy}) â†’ depth = {depth_val:.3f}")

                    msgs.append({
                        "class": int(classes[i]),
                        "cx":    cx,
                        "cy":    cy,
                        "depth": depth_val
                    })

                # --- í´ë˜ìŠ¤ë³„ë¡œ í•˜ë‚˜ë§Œ ì„ íƒ (ì˜ˆ: Depthê°€ ì‘ì€ ê²ƒ ìš°ì„ ) ---
                best_dets = {}
                for det in msgs:
                    cls = det["class"]
                    # ì²˜ìŒ ë“¤ì–´ì˜¤ê±°ë‚˜, ë” ì‘ì€ depth ë©´ êµì²´
                    if cls not in best_dets or det["depth"] > best_dets[cls]["depth"]:
                        best_dets[cls] = det

                # í”„ë ˆì„ ë‹¨ìœ„ë¡œ í•œ ë²ˆì—
                final_msgs = list(best_dets.values())
                frame_msg = {
                    "time":       time.time(),
                    "detections": final_msgs
                }
                pub.send_string(json.dumps(frame_msg))

                # (ì„ íƒ) ì‹œê°í™” ë° ì €ì¥
                vis = bbox_result.plot()
                cv2.imshow("YOLO+Depth", vis)

                if SAVE_VIDEO and video_writer is not None:
                    video_writer.write(vis)

            frame_idx += 1
            if cv2.waitKey(1) == ord('q'):
                break

    except KeyboardInterrupt:
        print("\nâ¹ï¸  ì‚¬ìš©ì ì¤‘ë‹¨")

    # --- ë§ˆë¬´ë¦¬ ---
    cap.release()
    if video_writer is not None:
        video_writer.release()
        print("ğŸ¬ Video saved successfully.")

if __name__ == "__main__":
    main()
