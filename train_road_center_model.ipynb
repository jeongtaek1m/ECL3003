{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. (Optional) Extract video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "capture = cv2.VideoCapture(\"test_video.avi\")\n",
    "assert capture.isOpened(), \"Cannot open the video file.\"\n",
    "\n",
    "num_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Prepare folders\n",
    "img_filename_fmt = 'dataset/images/frame_{:09d}.jpg'\n",
    "dirname = os.path.dirname(img_filename_fmt)\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "for ii in range(num_frames):\n",
    "    _, frame = capture.read()\n",
    "    cv2.imwrite(img_filename_fmt.format(ii), frame)\n",
    "\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Label images\n",
    "\n",
    "- Assume all images have same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "from ipywidgets import IntSlider, Label, Button, HBox\n",
    "from ipycanvas import MultiCanvas, hold_canvas\n",
    "\n",
    "thickness = 3\n",
    "y_ratio = 0.8     # percentile of y-position from the top\n",
    "\n",
    "# Input images\n",
    "img_filename_fmt = 'dataset/images/frame_{:09d}.jpg'\n",
    "ann_filename = 'dataset/annotation.txt'\n",
    "ann_dict = OrderedDict()\n",
    "\n",
    "num_frames = len(os.listdir(os.path.dirname(img_filename_fmt)))\n",
    "\n",
    "cur_index = 0\n",
    "height, width = cv2.imread(img_filename_fmt.format(cur_index)).shape[:2]\n",
    "y_value = int(height * y_ratio)\n",
    "\n",
    "def set_image():\n",
    "    image = cv2.imread(img_filename_fmt.format(cur_index))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image[y_value-thickness//2:y_value+thickness//2] = (255, 0, 0)\n",
    "\n",
    "    canvas[0].clear()\n",
    "    canvas[0].put_image_data(image, 0, 0)\n",
    "    canvas[0].flush()\n",
    "\n",
    "    pos = ann_dict.get(img_filename_fmt.format(cur_index))\n",
    "    if pos is not None:\n",
    "        handle_mouse_down(pos[0], pos[1])\n",
    "\n",
    "    cur_fname.value = 'Current image: {:s} | '.format(img_filename_fmt.format(cur_index))\n",
    "\n",
    "def handle_mouse_move(xpos, ypos):\n",
    "    with hold_canvas():\n",
    "        canvas[1].clear()  # Clear the old animation step\n",
    "        canvas[1].fill_style = \"yellow\"\n",
    "        canvas[1].fill_circle(xpos, y_value, 5)  # Draw the new frame\n",
    "\n",
    "def handle_mouse_down(xpos, ypos):\n",
    "    with hold_canvas():\n",
    "        canvas[2].clear()\n",
    "        canvas[2].fill_style = \"green\"\n",
    "        canvas[2].fill_circle(xpos, y_value, 5)  # Draw the new frame\n",
    "\n",
    "    cur_pos.value = \"({}, {}) \".format(int(xpos), int(y_value))\n",
    "    ann_dict[img_filename_fmt.format(cur_index)] = (xpos, y_value)\n",
    "\n",
    "def handle_slider_change(change):\n",
    "    global y_value\n",
    "    y_value = change.new\n",
    "    set_image()\n",
    "    canvas[1].clear()\n",
    "    canvas[2].clear()\n",
    "\n",
    "def handle_save_button(b):\n",
    "    with open(ann_filename, 'w') as f:\n",
    "        for k, v in ann_dict.items():\n",
    "            f.write(\"{}\\t{}\\t{}\\n\".format(k, int(v[0]), int(v[1])))\n",
    "\n",
    "def handle_prev_button(b):\n",
    "    global cur_index\n",
    "    cur_index = max(0, cur_index - 1)\n",
    "    canvas.clear()\n",
    "    set_image()\n",
    "\n",
    "def handle_next_button(b):\n",
    "    global cur_index\n",
    "    cur_index = min(num_frames - 1, cur_index + 1)\n",
    "    canvas.clear()\n",
    "    set_image()\n",
    "\n",
    "canvas = MultiCanvas(3, width=width, height=height)\n",
    "cur_fname = Label(value='', disabled=False)\n",
    "cur_pos = Label(value='', disabled=True)\n",
    "yslider = IntSlider(description=\"Y-bar: \", stype={'description_width': 'initial'}, value=y_value, min=1, max=height-2, step=1)\n",
    "prev_btn = Button(description='Prev', icon='arrow-left')\n",
    "next_btn = Button(description='Next', icon='arrow-right')\n",
    "save_btn = Button(description='Save labels', icon='check')\n",
    "\n",
    "set_image()\n",
    "canvas.on_mouse_move(handle_mouse_move)\n",
    "canvas.on_mouse_down(handle_mouse_down)\n",
    "yslider.observe(handle_slider_change, names='value')\n",
    "\n",
    "prev_btn.on_click(handle_prev_button)\n",
    "next_btn.on_click(handle_next_button)\n",
    "save_btn.on_click(handle_save_button)\n",
    "\n",
    "display(canvas, HBox([cur_fname, cur_pos, yslider]), HBox([prev_btn, next_btn, save_btn]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "def get_model():\n",
    "    model = torchvision.models.alexnet(num_classes=2, dropout=0.0)\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = get_model()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cnn.center_dataset import CenterDataset\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataset = CenterDataset('dataset', random_hflip=False)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import torch.nn.functional as f\n",
    "\n",
    "epoch = 200\n",
    "learning_rate = 2e-3\n",
    "# learning_rate = 2e-4\n",
    "\n",
    "epoch_slider = ipywidgets.IntSlider(description='Epochs', value=epoch, min=1, max=200, step=1)\n",
    "lr_slider = ipywidgets.FloatSlider(description='lr', value=learning_rate, min=1e-4, max=1e-2, step=1e-4, readout_format='.4f')\n",
    "train_button = ipywidgets.Button(description='Train', icon='tasks')\n",
    "loss_text = ipywidgets.Textarea(description='Progress', value='', rows=15, layout=ipywidgets.Layout(width=\"50%\", height=\"auto\"))\n",
    "layout = ipywidgets.VBox([ipywidgets.HBox([epoch_slider, lr_slider, train_button]), loss_text])\n",
    "\n",
    "\n",
    "def train_model(b):\n",
    "    global epoch_slider\n",
    "    for epoch in range(epoch_slider.value):\n",
    "        loss_text.value += \"<<<<< Epoch {:d} >>>>>\\n\".format(epoch)\n",
    "        train_step()\n",
    "\n",
    "\n",
    "def train_step():\n",
    "    global model, lr_slider, loss_text, train_laoder, device\n",
    "\n",
    "    try:\n",
    "        # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr_slider.value, momentum=0.9)\n",
    "\n",
    "        train_button.disabled = True\n",
    "        model = model.train()\n",
    "\n",
    "        num_iters = len(train_loader)\n",
    "        for ii, (images, labels) in enumerate(train_loader):\n",
    "            # send data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero gradients of parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # execute model to get outputs\n",
    "            outputs = model(images)\n",
    "\n",
    "            # compute MSE loss over x coordinates\n",
    "            loss = f.mse_loss(outputs, labels, reduction='sum')\n",
    "\n",
    "            # run backpropogation to accumulate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step optimizer to adjust parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            if ii % 10 == 0:\n",
    "                xlbl, ylbl = labels[0].cpu()\n",
    "                xlbl = ( xlbl.item() / 2 + 0.5 ) * 800\n",
    "                ylbl = ( ylbl.item() / 2 + 0.5 ) * 450\n",
    "\n",
    "                xpre, ypre = outputs[0].cpu()\n",
    "                xpre = ( xpre.item() / 2 + 0.5 ) * 800\n",
    "                ypre = ( ypre.item() / 2 + 0.5 ) * 450\n",
    "\n",
    "                msg = \"[{:04d} / {:04d}] loss: {:.4f} | labels: ({:.2f}, {:.2f}), outpus: ({:.2f}, {:.2f})\\n\".format(ii, num_iters, loss.item(), xlbl, ylbl, xpre, ypre)\n",
    "                loss_text.value += msg\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "    model = model.eval()\n",
    "    torch.save(model.state_dict(), 'road_following_model.pth')\n",
    "\n",
    "    train_button.disabled = False\n",
    "\n",
    "train_button.on_click(train_model)\n",
    "\n",
    "display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from cnn.center_dataset import TEST_TRANSFORMS\n",
    "\n",
    "def preprocess(image: PIL.Image):\n",
    "    device = torch.device('cuda')\n",
    "    image = TEST_TRANSFORMS(image).to(device)\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.load_state_dict(torch.load('road_following_model.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# from torch2trt import TRTModule\n",
    "# model = TRTModule()\n",
    "# model.load_state_dict(torch.load('road_following_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "img_filename_fmt = 'dataset/images/frame_{:09d}.jpg'\n",
    "ann_filename = 'dataset/annotation.txt'\n",
    "with open(ann_filename, 'r') as f:\n",
    "    data = [line.split() for line in f.readlines()]\n",
    "\n",
    "filename, xpos, ypos = data[3]\n",
    "\n",
    "xpos = int(xpos)\n",
    "ypos = int(ypos)\n",
    "\n",
    "image_ori = PIL.Image.open(filename)\n",
    "width = image_ori.width\n",
    "height = image_ori.height\n",
    "\n",
    "with torch.no_grad():\n",
    "    image = preprocess(image_ori)\n",
    "    output = model(image).detach().cpu().numpy()\n",
    "x, y = output[0]\n",
    "\n",
    "x = (x / 2 + 0.5) * width\n",
    "y = (y / 2 + 0.5) * height\n",
    "print(x, y)\n",
    "\n",
    "image_np = copy.deepcopy(np.asarray(image_ori))\n",
    "cv2.circle(image_np, (int(x), int(y)), radius=5, color=(255, 0, 0))  # Pred\n",
    "cv2.circle(image_np, (xpos, ypos), radius=5, color=(0, 255, 0))     # GT\n",
    "\n",
    "PIL.Image.fromarray(image_np)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
